import streamlit as st
import pandas as pd
import io
import re
from urllib.parse import urlparse

# Page config
st.set_page_config(
    page_title="URL Redirect Mapping Tool",
    page_icon="ðŸ”„",
    layout="wide"
)

# App header
st.title("URL Redirect Mapping Tool")
st.markdown("""
Deze tool helpt bij het maken van URL-redirects. 
Upload twee bestanden met URLs en kies hoe je ze wilt matchen.
""")

# Hulpfuncties
def validate_url(url):
    """Valideer of een string een geldige URL is."""
    if not url or pd.isna(url):
        return False
    
    # Eenvoudige URL-validatie
    url_pattern = re.compile(
        r'^(https?://)?'  # http:// of https://
        r'([a-zA-Z0-9-]+\.)*[a-zA-Z0-9-]+\.[a-zA-Z]{2,}'  # domein
        r'(/.*)?$'  # pad
    )
    return bool(url_pattern.match(url))

def extract_language_code(url):
    """Extraheert de taalcode uit een URL."""
    if not url or pd.isna(url):
        return None
    
    # Parsen van de URL
    parsed = urlparse(url)
    domain = parsed.netloc
    path = parsed.path
    
    # Controleren op taalcode in subdomein (bijv. fr.example.com)
    if domain.count('.') > 1:
        subdomain = domain.split('.')[0]
        if len(subdomain) == 2 or (len(subdomain) == 5 and subdomain[2] == '-'):
            return subdomain
    
    # Controleren op taalcode in pad (bijv. example.com/fr/)
    if path.startswith('/'):
        parts = path.split('/')
        if len(parts) > 1 and parts[1]:
            lang = parts[1]
            if len(lang) == 2 or (len(lang) == 5 and lang[2] == '-'):
                return lang
    
    return None

def detect_url_structure(urls):
    """Detecteert de structuur van URLs en extraheert de taalcodes."""
    language_patterns = {}
    domain_patterns = {}
    
    for url in urls:
        if not url or pd.isna(url):
            continue
            
        lang_code = extract_language_code(url)
        if lang_code:
            language_patterns[url] = lang_code
            
        # Domein extraheren
        parsed = urlparse(url)
        domain = parsed.netloc
        domain_patterns[url] = domain
    
    return language_patterns, domain_patterns

def generate_htaccess(source_urls, target_urls):
    """Genereer .htaccess regels voor de gegeven URLs."""
    htaccess_content = "# Redirect mappings generated by URL Redirect Mapper\n"
    htaccess_content += "# Format: RedirectPermanent source_path target_url\n\n"
    htaccess_content += "RewriteEngine On\n\n"
    
    for source, target in zip(source_urls, target_urls):
        if pd.isna(source) or pd.isna(target):
            continue
            
        # Extract source path
        if "://" in source:
            source_path = source.split("://", 1)[1]
            if "/" in source_path:
                source_path = "/" + source_path.split("/", 1)[1]
            else:
                source_path = "/"
        else:
            source_path = source
        
        htaccess_content += f"RedirectPermanent {source_path} {target}\n"
    
    return htaccess_content

# Main panel for data upload
col1, col2 = st.columns(2)

with col1:
    st.subheader("Bestand met bron-URLs")
    source_file = st.file_uploader("Upload CSV-bestand (bijv. fr-fr URLs)", type=["csv"], key="source_file")

with col2:
    st.subheader("Bestand met doel-URLs")
    target_file = st.file_uploader("Upload CSV-bestand (bijv. en-nl URLs)", type=["csv"], key="target_file")

if source_file is not None and target_file is not None:
    try:
        # Inlezen van CSV-bestanden
        source_df = pd.read_csv(source_file)
        target_df = pd.read_csv(target_file)
        
        st.success(f"Bestanden succesvol geladen: {source_file.name} en {target_file.name}")
        
        # Toon voorbeeld van beide bestanden
        st.subheader("Voorbeeld van geÃ¼ploade data")
        
        with col1:
            st.write("Bronbestand (eerste 5 rijen):")
            st.dataframe(source_df.head())
            
        with col2:
            st.write("Doelbestand (eerste 5 rijen):")
            st.dataframe(target_df.head())
        
        # Laat de gebruiker kolommen kiezen
        st.subheader("Selecteer kolommen")
        
        source_cols = list(source_df.columns)
        target_cols = list(target_df.columns)
        
        source_col = st.selectbox("Selecteer de kolom met bron-URLs", source_cols, index=0)
        target_col = st.selectbox("Selecteer de kolom met doel-URLs", target_cols, index=0)
        
        # Matching opties
        st.subheader("Matching-opties")
        
        matching_option = st.radio(
            "Hoe wil je de URLs matchen?",
            [
                "EÃ©n-op-Ã©Ã©n (bestanden moeten evenveel rijen hebben)",
                "Op basis van padstructuur (taalvarianten automatisch detecteren)",
                "Op basis van positie (rij 1 van bron matcht met rij 1 van doel, etc.)"
            ]
        )
        
        # Analyse van URL-structuren
        source_urls = source_df[source_col].tolist()
        target_urls = target_df[target_col].tolist()
        
        source_langs, source_domains = detect_url_structure(source_urls)
        target_langs, target_domains = detect_url_structure(target_urls)
        
        # Toon gedetecteerde taalcodes
        if len(source_langs) > 0 or len(target_langs) > 0:
            st.subheader("Gedetecteerde taalcodes")
            
            # Toon voorbeelden van gedetecteerde taalcodes in beide bestanden
            col1, col2 = st.columns(2)
            
            with col1:
                st.write("Taalcodes in bronbestand:")
                seen_langs = set()
                for url, lang in list(source_langs.items())[:5]:  # Eerste 5 als voorbeeld
                    if lang not in seen_langs:
                        st.write(f"- `{lang}` in URL: {url}")
                        seen_langs.add(lang)
            
            with col2:
                st.write("Taalcodes in doelbestand:")
                seen_langs = set()
                for url, lang in list(target_langs.items())[:5]:  # Eerste 5 als voorbeeld
                    if lang not in seen_langs:
                        st.write(f"- `{lang}` in URL: {url}")
                        seen_langs.add(lang)
        
        if st.button("Genereer URL-mappings"):
            # De mappings genereren op basis van de gekozen optie
            if matching_option.startswith("EÃ©n-op-Ã©Ã©n"):
                # Controleer of beide bestanden evenveel rijen hebben
                if len(source_df) != len(target_df):
                    st.error(f"De bestanden hebben een verschillend aantal rijen: {len(source_df)} in bronbestand, {len(target_df)} in doelbestand.")
                else:
                    # Valideren van URLs
                    source_df['bron_valide'] = source_df[source_col].apply(validate_url)
                    target_df['doel_valide'] = target_df[target_col].apply(validate_url)
                    
                    # Combineer de gegevens
                    combined_df = pd.DataFrame({
                        'bron_url': source_df[source_col],
                        'doel_url': target_df[target_col],
                        'bron_valide': source_df['bron_valide'],
                        'doel_valide': target_df['doel_valide']
                    })
                    
                    # Verwerk de resultaten
                    process_results(combined_df)
                    
            elif matching_option.startswith("Op basis van padstructuur"):
                # Intelligent matchen op basis van URL-structuur
                matches = []
                
                # Als we domein- en padstructuur matchen
                for i, source_url in enumerate(source_urls):
                    source_lang = source_langs.get(source_url)
                    source_domain = source_domains.get(source_url)
                    
                    if not source_lang or not source_domain:
                        continue
                    
                    source_path = None
                    if "://" in source_url:
                        try:
                            source_path = source_url.split("://", 1)[1].split("/", 1)[1] if "/" in source_url.split("://", 1)[1] else ""
                        except:
                            source_path = ""
                    
                    best_match = None
                    for target_url in target_urls:
                        target_lang = target_langs.get(target_url)
                        target_domain = target_domains.get(target_url)
                        
                        if not target_lang or not target_domain:
                            continue
                        
                        target_path = None
                        if "://" in target_url:
                            try:
                                target_path = target_url.split("://", 1)[1].split("/", 1)[1] if "/" in target_url.split("://", 1)[1] else ""
                            except:
                                target_path = ""
                        
                        # Als de padstructuur overeenkomt, maar de taalcodes verschillen
                        # Dit is wat we willen voor taalvarianten
                        if source_path == target_path and source_lang != target_lang:
                            best_match = target_url
                            break
                    
                    if best_match:
                        matches.append({
                            'bron_url': source_url,
                            'doel_url': best_match,
                            'bron_valide': True,
                            'doel_valide': True
                        })
                    else:
                        matches.append({
                            'bron_url': source_url,
                            'doel_url': None,
                            'bron_valide': True,
                            'doel_valide': False
                        })
                
                # Verwerk de resultaten
                if matches:
                    combined_df = pd.DataFrame(matches)
                    process_results(combined_df)
                else:
                    st.warning("Geen matches gevonden op basis van padstructuur. Probeer een andere matching-optie.")
                    
            elif matching_option.startswith("Op basis van positie"):
                # Zorg ervoor dat we niet buiten de grenzen gaan
                min_rows = min(len(source_df), len(target_df))
                
                # Valideren van URLs
                source_df['bron_valide'] = source_df[source_col].apply(validate_url)
                target_df['doel_valide'] = target_df[target_col].apply(validate_url)
                
                # Combineer de gegevens (alleen de eerste min_rows rijen)
                combined_df = pd.DataFrame({
                    'bron_url': source_df[source_col].iloc[:min_rows],
                    'doel_url': target_df[target_col].iloc[:min_rows],
                    'bron_valide': source_df['bron_valide'].iloc[:min_rows],
                    'doel_valide': target_df['doel_valide'].iloc[:min_rows]
                })
                
                # Verwerk de resultaten
                process_results(combined_df)
                
                # Waarschuwing als bestanden niet evenveel rijen hebben
                if len(source_df) != len(target_df):
                    st.warning(f"De bestanden hebben een verschillend aantal rijen. Alleen de eerste {min_rows} rijen zijn gebruikt.")
    
    except Exception as e:
        st.error(f"Fout bij het verwerken van de bestanden: {str(e)}")
        st.exception(e)

def process_results(combined_df):
    """Verwerk en toon de resultaten"""
    # Tellen van geldige en ongeldige URLs
    valide_rijen = combined_df['bron_valide'] & combined_df['doel_valide']
    valide_aantal = valide_rijen.sum()
    ongeldig_aantal = len(combined_df) - valide_aantal
    
    # Toon statistieken
    col1, col2 = st.columns(2)
    col1.metric("Geldige URL-paren", valide_aantal)
    col2.metric("Ongeldige URL-paren", ongeldig_aantal)
    
    if ongeldig_aantal > 0:
        st.warning(f"Er zijn {ongeldig_aantal} ongeldige URL-paren gevonden. Deze worden gemarkeerd in de output.")
    
    # Toon resultaat
    st.write("Gevalideerde resultaten:")
    st.dataframe(combined_df)
    
    # Export opties
    st.subheader("Exporteren")
    
    # Excel export
    excel_buffer = io.BytesIO()
    with pd.ExcelWriter(excel_buffer, engine='openpyxl') as writer:
        combined_df.to_excel(writer, index=False, sheet_name='Redirects')
    
    st.download_button(
        label="Download als Excel (.xlsx)",
        data=excel_buffer.getvalue(),
        file_name="redirect_mappings.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )
    
    # CSV export
    csv = combined_df.to_csv(index=False).encode('utf-8')
    st.download_button(
        label="Download als CSV",
        data=csv,
        file_name="redirect_mappings.csv",
        mime="text/csv",
    )
    
    # .htaccess export
    htaccess_content = generate_htaccess(
        combined_df[valide_rijen]['bron_url'],
        combined_df[valide_rijen]['doel_url']
    )
    
    st.download_button(
        label="Download als .htaccess",
        data=htaccess_content,
        file_name="redirects.htaccess",
        mime="text/plain",
    )

# Sidebar met instructies
with st.sidebar:
    st.header("Instructies")
    st.markdown("""
    1. **Upload twee CSV-bestanden**:
       - Bestand 1: URLs in Ã©Ã©n taalvariant (bijv. fr-fr)
       - Bestand 2: URLs in andere taalvariant (bijv. en-nl)
       
    2. **Selecteer de kolommen** die de URLs bevatten
    
    3. **Kies een matching-optie**:
       - **EÃ©n-op-Ã©Ã©n**: Eerste URL in bestand 1 matcht met eerste URL in bestand 2, etc.
       - **Padstructuur**: URLs met vergelijkbare paden maar verschillende taalcodes worden gematcht
       - **Positie**: Simpelweg op basis van rijpositie matchen
    
    4. **Genereer URL-mappings**
    
    5. **Download de resultaten** in het gewenste formaat
    """)
    
    st.header("Voorbeeld CSV formaat")
    
    st.write("**Bestand 1 (fr-fr URLs):**")
    st.code("""url
https://fr-fr.example.com/nouvelles
https://fr-fr.example.com/entreprise
https://fr-fr.example.com/produits""")
    
    st.write("**Bestand 2 (en-nl URLs):**")
    st.code("""url
https://en-nl.example.com/news
https://en-nl.example.com/company
https://en-nl.example.com/products""")

# Footer
st.markdown("---")
st.markdown("URL Redirect Mapping Tool Â© 2023") 